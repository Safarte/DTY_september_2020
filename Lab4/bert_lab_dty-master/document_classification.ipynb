{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iT5HwwZnFHWG"
   },
   "source": [
    "# BERT Lab 3: Document Classification\n",
    "\n",
    "In this third lab, we'll see how to fine-tune BERT for docuement classification using the Wikipedia Personal Atacks as an example.\n",
    "\n",
    "In the last lab, we applied BERT to sentence classification, in this lab, we'll lood at longer pieces of text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 92
    },
    "colab_type": "code",
    "id": "cI2SVj-ZHuHP",
    "outputId": "98cb7192-4112-43ef-b320-26790aacdf2c"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import logging\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import TensorDataset, random_split, DataLoader, RandomSampler, SequentialSampler\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GnP_imlGFHWP"
   },
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3wVAOFOrFHWT"
   },
   "source": [
    "As always, let's start with setting the correct device and installing the transformers library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "aJGzrTU6FHWU",
    "outputId": "bae7709b-6876-43a2-9127-682d463b8f7a"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():    \n",
    "    device = torch.device(\"cuda\")\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    assert False, \"Please select GPU in the Colab\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 661
    },
    "colab_type": "code",
    "id": "l9qtCcRdFHWa",
    "outputId": "ed57208b-c824-4c3e-da1d-a97f4a2f5905"
   },
   "outputs": [],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cS6FJ9_iFHWg"
   },
   "source": [
    "### Dataset\n",
    "\n",
    "As stated earlier, we'll use Wikipedia Personal Attacks. The dataset is a corpus of discussion comments from English Wikipedia talk pages. Comments are grouped into different files by year. And the objective is to classify of the coments contains some personal attacks or not. So like CoLA dataset, we'll being doing a binary classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pHfpRDP_FHWh"
   },
   "source": [
    "First, we'll download the datasetn then use `pandas` to parse the `.tsv` file, and we'll use the BERT tokenizer to pre-process the input data for our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90
    },
    "colab_type": "code",
    "id": "8TQ5Su33HuHc",
    "outputId": "504aa98b-44f8-4748-e076-f6c33c932566"
   },
   "outputs": [],
   "source": [
    "# Downloading the dataset\n",
    "import urllib.request as request\n",
    "import os\n",
    "\n",
    "if not os.path.exists(\"./Wikipedia_Talk_Labels\"):\n",
    "    os.mkdir(\"./Wikipedia_Talk_Labels\")\n",
    "\n",
    "files = [\n",
    "    (\"./Wikipedia_Talk_Labels/attack_annotated_comments.tsv\", \"https://ndownloader.figshare.com/files/7554634\"),\n",
    "    (\"./Wikipedia_Talk_Labels/attack_annotations.tsv\", \"https://ndownloader.figshare.com/files/7554637\")\n",
    "]\n",
    "\n",
    "for (filename, url) in files:\n",
    "    if not os.path.exists(filename):\n",
    "        print(\"Downloading\", filename)\n",
    "        request.urlretrieve(url, filename)\n",
    "        print(\"    Done ....\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 127
    },
    "colab_type": "code",
    "id": "j78QN7XfHuHo",
    "outputId": "b90e2027-c1f2-423d-ecd7-12e6636f1374"
   },
   "outputs": [],
   "source": [
    "# Parse file\n",
    "import pandas as pd\n",
    "print(\"Parsing the dataset .tsv file ...\")\n",
    "\n",
    "comments = pd.read_csv(files[0][0], sep=\"\\t\", index_col=0)\n",
    "annotations = pd.read_csv(files[1][0], sep=\"\\t\")\n",
    "\n",
    "dataset_sizes = comments[[\"comment\", \"split\"]].groupby(\"split\").count()\n",
    "print(\"Dataset Sizes: {}\".format(dataset_sizes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y5QWtklhFHWt"
   },
   "source": [
    "Let's see a few row to see what we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "id": "KSfKlLwbFHWu",
    "outputId": "7dcca10a-227e-4817-d0a2-400ebd3ca28a"
   },
   "outputs": [],
   "source": [
    "# Display the first row of the table\n",
    "comments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "colab_type": "code",
    "id": "eHOC9eU0FHWz",
    "outputId": "07d3c3bf-8040-4dcb-c009-9744d0f39e70"
   },
   "outputs": [],
   "source": [
    "annotations.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "udO8wFZOFHW2"
   },
   "source": [
    "We are provided with three splits, let's see how big are each one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "colab_type": "code",
    "id": "oBSzn68gFHW3",
    "outputId": "04b9bccc-367a-479c-8060-53739dde4985"
   },
   "outputs": [],
   "source": [
    "# See the sizes of each split\n",
    "comments[[\"comment\", \"split\"]].groupby('split').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SYxG3Lg6FHW8"
   },
   "source": [
    "#### Labels\n",
    "\n",
    "The comments are uniquely indentified by their 'rev_id'. And the annotation table has multiple rown for each comment beacause we have multiple labelers. And we'll consider a comment as an attack  if the majority of the annotators agree that it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "colab_type": "code",
    "id": "evbqJsjRHuHx",
    "outputId": "717797e6-1e8b-4716-ec9b-cf6a02c34f2a"
   },
   "outputs": [],
   "source": [
    "# A comment is an attack if the majority of the annotators agree\n",
    "labels = annotations.groupby(\"rev_id\")[\"attack\"].mean() > 0.5\n",
    "comments[\"attack\"] = labels\n",
    "\n",
    "# remove newline and tab tokens\n",
    "comments[\"comment\"] = comments[\"comment\"].apply(lambda x: x.replace(\"NEWLINE_TOKEN\", \" \"))\n",
    "comments[\"comment\"] = comments[\"comment\"].apply(lambda x: x.replace(\"TAB_TOKEN\", \" \"))\n",
    "\n",
    "comments.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zARHhH-6FHXC"
   },
   "source": [
    "Now, let's divide the dataset into training and validation and testing comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aAfbac1uHuH5"
   },
   "outputs": [],
   "source": [
    "# Splits\n",
    "\n",
    "train_comments = comments.query(\"split=='train'\")\n",
    "val_comments = comments.query(\"split=='dev'\")\n",
    "test_comments = comments.query(\"split=='test'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S-p-gMcvFHXH"
   },
   "source": [
    "Let's display some of the comments labeled as containing an attack. We'll use `textwrap` to wrap a single paragraph in text, and return a single string containing the wrapped paragraph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 715
    },
    "colab_type": "code",
    "id": "4a1N4RRDHuIA",
    "outputId": "000098c3-4c02-40d8-b509-ff4de952d51a"
   },
   "outputs": [],
   "source": [
    "import textwrap\n",
    "import random\n",
    "\n",
    "# Get some positive samples (comments with attacks)\n",
    "wrapper = textwrap.TextWrapper(width=80)\n",
    "attack_examples = train_comments.query(\"attack\")[\"comment\"]\n",
    "\n",
    "for i in range(10):\n",
    "    j = random.choice(attack_examples.index)\n",
    "    print(wrapper.fill(attack_examples[j]))\n",
    "    print(\" ---------- \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SJRfH6GXFHXN"
   },
   "source": [
    "Some stats on the distribution of labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "Wkux2sl3HuIJ",
    "outputId": "04dbbb0f-defd-4137-b25f-487b29217335"
   },
   "outputs": [],
   "source": [
    "total_comments = comments.shape[0]\n",
    "num_attacks = comments.query(\"attack\").shape[0]\n",
    "\n",
    "print(f\"Percentage of attack comments {(num_attacks / total_comments) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gBDRRRuNFHXR"
   },
   "source": [
    "As we can see, this is a highly imbalanced classes, so predicting 0 will give us 88% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "Avc4Yl78FHXS",
    "outputId": "e105a081-4505-4b8d-e22f-d61ef707297d"
   },
   "outputs": [],
   "source": [
    "labels = train_comments.attack.to_numpy().astype(int)\n",
    "print(f\"Number of positive comments {labels.sum()} and negative ones {len(labels) - labels.sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gTK99cnBFHXX"
   },
   "source": [
    "## Tokenization & BERT input length limitation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h1561wnrFHXX"
   },
   "source": [
    "Like we've discussed in the introduction, BERT has a maximum of 512 tokens. In this part of the lab, we'll look at how this limitation can affect us in practive. And present some possible approaches to address it.\n",
    "\n",
    "Let's start by seeing the distribution of lengths of the tokenized comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104,
     "referenced_widgets": [
      "59455a00ffae49e8a73c6e692c0d8ec0",
      "a8663c8af9d84daa8e8c6c22640cbe92",
      "f61cb694a31f494099ee6b0d3118545f",
      "d98f0a6f4f20469da847af5177afedac",
      "13f431ba57cc47649e296d0d5ff98a90",
      "9287ff6f4db148608f101b2e853fed88",
      "d6e998f546b64cbe961878210482800e",
      "4d597407e151461fa15a2f6d87f9aae0"
     ]
    },
    "colab_type": "code",
    "id": "vM_i3FY_FHXY",
    "outputId": "3b51a0f4-fb99-4b87-92a8-95cce431981b"
   },
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "# Avoid printing warnings\n",
    "import logging\n",
    "logging.getLogger(\"transformers\").setLevel(logging.ERROR)\n",
    "\n",
    "# Tokenizer the comments\n",
    "input_ids, lengths = [], []\n",
    "\n",
    "# Load the BERT tokenizer.\n",
    "print('Loading BERT tokenizer...')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "\n",
    "print(\"Tokenizing comments ....\")\n",
    "input_ids = [tokenizer.encode(s, add_special_tokens=True) for s in tqdm(train_comments.comment)]\n",
    "lengths = [len(input_id) for input_id in input_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 390
    },
    "colab_type": "code",
    "id": "tN98_ax1FHXb",
    "outputId": "4bd8b980-2214-443e-c42b-294def978cc1"
   },
   "outputs": [],
   "source": [
    "# Plot the distribution of comment lengths\n",
    "\n",
    "# Set style\n",
    "sns.set(style=\"darkgrid\")\n",
    "sns.set(font_scale=1.5)\n",
    "plt.rcParams[\"figure.figsize\"] = (10,5)\n",
    "\n",
    "# Consider all length > 512 as equal to 512, if not the distribution will be skewed\n",
    "lengths_shortened = [min(l, 512) for l in lengths]\n",
    "sns.distplot(lengths_shortened, kde=False, rug=False)\n",
    "\n",
    "plt.xlabel(\"Comments length\")\n",
    "plt.ylabel(\"# Comments\")\n",
    "plt.title(\"Comment lengths\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q0bAkXhgFHXf"
   },
   "source": [
    "#### Solutions:\n",
    "\n",
    "But how can we solve this problem? There's no obvious solution, but we can some solutions to help solve this. There are two simple and straightforward approaches that we can try:\n",
    "\n",
    "\n",
    "**Truncation:**\n",
    "The first solution is to simply drop some of the tokens, and hope that the remaining text is enough to predict the correct label.\n",
    "But what tokens should we drop? we can drop:\n",
    "- From the beginning.\n",
    "- At the end.\n",
    "- In this middle.\n",
    "- At a random starting position.\n",
    "\n",
    "In this [paper](https://arxiv.org/abs/1905.05583), the auhors experimented on IMDb movie dataset, and showed that keeping the first 125 tokens and the last 382 tokens, so the total number of tokens remaining is 512, leaving room for the two special tokens `[CLS]` and `[SEP]` that are neccessary to append for BERT fine-tunning.\n",
    "\n",
    "**Chunking:** \n",
    "The second solution is Chunking is to divide the test into 512-token chunks and generate embeddings for each of these chunks. These embeddings are then combined (like a simple summation or other pooling strategies) before performing the final classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8jONnj9SG3U5"
   },
   "source": [
    "##  <span style=\"color:red\">Your turn. </span>\n",
    "We use Truncation, and truncate all the inputs to max length of 128, similar to the second lab, here is what you'll need to do:\n",
    "\n",
    "1. **You first need the tokens if the lengh of the input sequence is > 128.**\n",
    "1. **Pad the sequences of length < 128.**\n",
    "1. **Create the attention masks to differentiate between the padding tokens and the rest of tokens.**\n",
    "1. **Split the data into train and validation: 90 %and 10% as in lab 2.**\n",
    "1. **Create the datasets and the dataloaders.**\n",
    "1. **Create the model and the optimizer using the same hyperparamters as lab, but only use 1 epoch.**\n",
    "1. **Fine-tune the BERT model for classification. Only train for one epoch, because the dataset is a bit big, and it'll take approx. 30min.**\n",
    "1. **Apply the same preprocessing to the test data (tokenizer, truncate, create dataset and dataloader).**\n",
    "1. **Apply the model to the test data.**\n",
    "1. **Given how imbalanced the dataset is, compute ROC AUC metric using [roc_auc_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html) on the test data. <span style=\"color:red\">The results should be > 0.95 </span>** \n",
    "\n",
    "Please use the second lab as a reference, the changes to be made are minimal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zHqAuCPcHuJm"
   },
   "outputs": [],
   "source": [
    "# Your turn"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "document_classification.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "13f431ba57cc47649e296d0d5ff98a90": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "4763a7a57f154500bc5b4f7cce7148be": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4d597407e151461fa15a2f6d87f9aae0": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "55368b3fe4b54f5a99b129cf81edc16a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_795fc4f6d35d4d91876fd8d8bf2d0e32",
      "max": 69526,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a0b2f13ce7604524adc4540e0a338407",
      "value": 69526
     }
    },
    "59455a00ffae49e8a73c6e692c0d8ec0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f61cb694a31f494099ee6b0d3118545f",
       "IPY_MODEL_d98f0a6f4f20469da847af5177afedac"
      ],
      "layout": "IPY_MODEL_a8663c8af9d84daa8e8c6c22640cbe92"
     }
    },
    "5c3104941f9f4570b5764e59580a84a2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_55368b3fe4b54f5a99b129cf81edc16a",
       "IPY_MODEL_dcf44fc2a62846f8a75281321560d05f"
      ],
      "layout": "IPY_MODEL_4763a7a57f154500bc5b4f7cce7148be"
     }
    },
    "795fc4f6d35d4d91876fd8d8bf2d0e32": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9287ff6f4db148608f101b2e853fed88": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a0b2f13ce7604524adc4540e0a338407": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "a8663c8af9d84daa8e8c6c22640cbe92": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a98a9ec8ff5f4577b70bb5245d7e0867": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d6e998f546b64cbe961878210482800e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d98f0a6f4f20469da847af5177afedac": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4d597407e151461fa15a2f6d87f9aae0",
      "placeholder": "​",
      "style": "IPY_MODEL_d6e998f546b64cbe961878210482800e",
      "value": " 69526/69526 [02:59&lt;00:00, 387.72it/s]"
     }
    },
    "dcf44fc2a62846f8a75281321560d05f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a98a9ec8ff5f4577b70bb5245d7e0867",
      "placeholder": "​",
      "style": "IPY_MODEL_f10c4c243c2746be9c2fd19799698a6b",
      "value": " 69526/69526 [03:13&lt;00:00, 360.01it/s]"
     }
    },
    "f10c4c243c2746be9c2fd19799698a6b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f61cb694a31f494099ee6b0d3118545f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9287ff6f4db148608f101b2e853fed88",
      "max": 69526,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_13f431ba57cc47649e296d0d5ff98a90",
      "value": 69526
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
